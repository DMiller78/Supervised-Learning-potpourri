{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as sns\n",
    "\n",
    "import chardet\n",
    "import codecs\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with the correct path for your data.\n",
    "df = pd.read_csv('/Users/mille/Desktop/Supervised learning potpourri/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Background on dataset: ***\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud#creditcard.csv\n",
    "\n",
    "**Context**\n",
    "\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "**Content**\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "**Inspiration**\n",
    "\n",
    "Identify fraudulent credit card transactions.\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Plan for working with data and modeling***\n",
    "\n",
    "Correlation matrix - exploratory analysis \n",
    "1. Random Forest \n",
    "2. Logistic Regression\n",
    "3. SVM \n",
    "\n",
    "\n",
    "Working on Normalizing credit card dataset: https://www.kaggle.com/gargmanish/how-to-handle-imbalance-data-study-in-detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22585fa8908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEBCAYAAABv4kJxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(\"Class\",data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of normal transacation is 99.82725143693798\n",
      "percentage of fraud transacation 0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "# now let us check in the number of Percentage\n",
    "Count_Normal_transacation = len(df[df[\"Class\"]==0]) # normal transaction are repersented by 0\n",
    "Count_Fraud_transacation = len(df[df[\"Class\"]==1]) # fraud by 1\n",
    "\n",
    "Percentage_of_Normal_transacation = Count_Normal_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of normal transacation is\",Percentage_of_Normal_transacation*100)\n",
    "\n",
    "Percentage_of_Fraud_transacation= Count_Fraud_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of fraud transacation\",Percentage_of_Fraud_transacation*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only a 0.17% of fraudulent transactions in credit cards. Meaning there is also 99.8% of valid transactions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2258ad82f28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAFvCAYAAABw2H4QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAALEDoAgAAsAChCwAAwAL/D2O3OXPkPXL/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fraud_transacation = df[df[\"Class\"]==1]\n",
    "Normal_transacation= df[df[\"Class\"]==0]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "Fraud_transacation.Amount.plot.hist(title=\"Fraud Transacation\")\n",
    "plt.subplot(122)\n",
    "Normal_transacation.Amount.plot.hist(title=\"Normal Transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for undersampling we need a portion of majority class and will take whole data of minority class\n",
    "# count fraud transaction is the total number of fraud transaction\n",
    "# now lets us see the index of fraud cases\n",
    "\n",
    "fraud_indices= np.array(df[df.Class==1].index)\n",
    "normal_indices = np.array(df[df.Class==0].index)\n",
    "\n",
    "#now let us a define a function for make undersample data with different proportion\n",
    "#different proportion means with different proportion of normal classes of data\n",
    "def undersample(normal_indices,fraud_indices,times):#times denote the normal data = times*fraud data\n",
    "    \n",
    "    Normal_indices_undersample = np.array(np.random.choice(normal_indices,(times*Count_Fraud_transacation),replace=False))\n",
    "    undersample_data= np.concatenate([fraud_indices,Normal_indices_undersample])\n",
    "    undersample_data = data.iloc[undersample_data,:]\n",
    "    \n",
    "    print(\"the normal transacation proportion is :\",len(undersample_data[undersample_data.Class==0])/len(undersample_data[undersample_data.Class]))\n",
    "    print(\"the fraud transacation proportion is :\",len(undersample_data[undersample_data.Class==1])/len(undersample_data[undersample_data.Class]))\n",
    "    print(\"total number of record in resampled data is:\",len(undersample_data[undersample_data.Class]))\n",
    "    return(undersample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first make a model function for modeling with confusion matrix\n",
    "def model(model,features_train,features_test,labels_train,labels_test):\n",
    "    clf= model\n",
    "    clf.fit(features_train,labels_train.values.ravel())\n",
    "    pred=clf.predict(features_test)\n",
    "    \n",
    "    cnf_matrix=confusion_matrix(labels_test,pred)\n",
    "    print(\"the recall for this model is :\",cnf_matrix[1,1]/(cnf_matrix[1,1]+cnf_matrix[1,0]))\n",
    "    fig= plt.figure(figsize=(6,3))# to plot the graph\n",
    "    print(\"TP\",cnf_matrix[1,1,]) # no of fraud transaction which are predicted fraud\n",
    "    print(\"TN\",cnf_matrix[0,0]) # no. of normal transaction which are predited normal\n",
    "    print(\"FP\",cnf_matrix[0,1]) # no of normal transaction which are predicted fraud\n",
    "    print(\"FN\",cnf_matrix[1,0]) # no of fraud Transaction which are predicted normal\n",
    "    \n",
    "    sns.heatmap(cnf_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n",
    "    plt.title(\"Confusion_matrix\")\n",
    "    plt.xlabel(\"Predicted_class\")\n",
    "    plt.ylabel(\"Real class\")\n",
    "    plt.show()\n",
    "    print(\"\\n----------Classification Report------------------------------------\")\n",
    "    print(classification_report(labels_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepration(x): # preparing data for training and testing as we are going to use different data \n",
    "    #again and again so make a function\n",
    "    x_features= x.ix[:,x.columns != \"Class\"]\n",
    "    x_labels=x.ix[:,x.columns==\"Class\"]\n",
    "    x_features_train,x_features_test,x_labels_train,x_labels_test = train_test_split(x_features,x_labels,test_size=0.3)\n",
    "    print(\"length of training data\")\n",
    "    print(len(x_features_train))\n",
    "    print(\"length of test data\")\n",
    "    print(len(x_features_test))\n",
    "    return(x_features_train,x_features_test,x_labels_train,x_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Normalized Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...               V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794        ...         -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974        ...         -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643        ...          0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952        ...         -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074        ...         -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \\\n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "\n",
       "   Normalized Amount  \n",
       "0           0.244964  \n",
       "1          -0.342475  \n",
       "2           1.160686  \n",
       "3           0.140534  \n",
       "4          -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before starting we should standridze our ampount column\n",
    "df[\"Normalized Amount\"] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df.drop([\"Time\",\"Amount\"],axis=1,inplace=True)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Assigning train data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test sizes.\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "df_test = df.iloc[trainsize:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train = df_train.drop(['Class'],1)\n",
    "target_train = df_train.Class\n",
    "\n",
    "data_test = df_test.drop(['Class'],1)\n",
    "target_test = df_test.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95519978, 0.9989467 , 0.99845516, 0.99943824, 0.99978933,\n",
       "       0.9994382 , 0.99957865, 0.9994382 , 0.99929775, 0.99915724])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "cross_val_score(rfc, data_train, target_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(data_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify, storing the result in a new variable.\n",
    "y_pred_test2= rfc.predict(data_test)\n",
    "y_pred_train2 = rfc.predict(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of mislabeled points out of a total 142403 points : 13\n",
      "Test: Number of mislabeled points out of a total 142404 points : 120\n"
     ]
    }
   ],
   "source": [
    "# Display our results.\n",
    "print(\"Train: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_train.shape[0],\n",
    "    (target_train != y_pred_train2).sum()\n",
    "))\n",
    "print(\"Test: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_test.shape[0],\n",
    "    (target_test != y_pred_test2).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1\n",
       "Class             \n",
       "0      142134    0\n",
       "1          13  256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(target_train, y_pred_train2)\n",
    "\n",
    "# 13/269 = 4.8% error fraud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest - fraud detection percentage of 4.8 % **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012630\n",
      "         Iterations 11\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   No. Observations:               284807\n",
      "Model:                          Logit   Df Residuals:                   284804\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 24 Mar 2019   Pseudo R-squ.:                0.006627\n",
      "Time:                        22:23:07   Log-Likelihood:                -3597.2\n",
      "converged:                       True   LL-Null:                       -3621.2\n",
      "                                        LLR p-value:                 3.778e-11\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Time       -6.337e-06   9.73e-07     -6.515      0.000   -8.24e-06   -4.43e-06\n",
      "Amount         0.0002   6.81e-05      3.030      0.002    7.28e-05       0.000\n",
      "intercept     -5.8239      0.091    -64.095      0.000      -6.002      -5.646\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Declare predictors.\n",
    "X_statsmod = df[['Time', 'Amount']]\n",
    "\n",
    "# The Statsmodels formulation requires a column with constant value 1 that\n",
    "# will act as the intercept.\n",
    "X_statsmod['intercept'] = 1 \n",
    "\n",
    "# Declare and fit the model.\n",
    "logit = sm.Logit(df['Class'], X_statsmod)\n",
    "result = logit.fit()\n",
    "#clear values 0 or 1 \n",
    "\n",
    "# Lots of information about the model and its coefficients, but the\n",
    "# accuracy rate for predictions is missing.\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15',\n",
    "       'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93838\n",
      "           1       0.65      0.48      0.55       149\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     93987\n",
      "   macro avg       0.83      0.74      0.77     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[-4.19618343e-06  8.96295488e-02  1.75838137e-03 -2.24648355e-02\n",
      "   6.94937311e-01  1.27089327e-01 -1.14701463e-01 -7.49020127e-02\n",
      "  -1.80013386e-01 -2.79981599e-01 -8.05510722e-01 -6.73780020e-02\n",
      "   9.05095174e-02 -3.31751921e-01 -5.60413595e-01 -1.18523162e-01\n",
      "  -1.93509053e-01 -2.89708239e-02 -6.21459618e-03  9.53632081e-02\n",
      "  -4.30467133e-01  3.93701139e-01  6.33324215e-01 -1.02336553e-01\n",
      "   1.28961399e-01 -8.42305585e-02  2.23620530e-02 -7.87257412e-01\n",
      "  -2.82082304e-01  7.75625487e-04]]\n",
      "[-8.32384054]\n",
      "\n",
      " Accuracy by admission status\n",
      "Class       0    1\n",
      "row_0             \n",
      "0      284273  184\n",
      "1          42  308\n",
      "\n",
      " Percentage accuracy\n",
      "0.9992064801778047\n"
     ]
    }
   ],
   "source": [
    "# Declare a lasso regression classifier.\n",
    "lasso_reg = LogisticRegression(penalty='l1', C=20)\n",
    "\n",
    "# Fit the model.\n",
    "lasso_fit = lasso_reg.fit(X, y)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(lasso_fit.coef_)\n",
    "print(lasso_fit.intercept_)\n",
    "pred_y_sklearn = lasso_reg.predict(X)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lasso_reg.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso - logistic regression has a 12% fraud detection rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99866582 0.99887648 0.999684   0.99898178 0.99884133 0.99912219\n",
      " 0.99961376 0.99908708 0.99922753 0.99901685]\n"
     ]
    }
   ],
   "source": [
    "lasso_scores = cross_val_score(lasso_reg, X, y, cv=10)\n",
    "print(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991116833155729\n"
     ]
    }
   ],
   "source": [
    "# Mean accuracy has improved slightly with penalty='l1' and C set to 20\n",
    "avg_lasso = np.mean(lasso_scores)\n",
    "print(np.mean(avg_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[-7.12203088e-05  3.18987791e-01 -4.84114993e-01 -7.93492991e-01\n",
      "   1.20293220e-01  5.74913980e-02 -5.40507839e-02  3.35304942e-01\n",
      "  -3.74343608e-01 -3.88595044e-01 -2.07045204e-01 -2.86734729e-01\n",
      "   1.86401142e-02 -3.06663722e-01 -6.94601310e-01 -4.27792172e-01\n",
      "  -2.94733914e-01 -4.39973718e-01  3.10696173e-02  2.65173298e-02\n",
      "   9.20001779e-02  2.48882503e-01  3.51023984e-01  6.77165121e-02\n",
      "  -2.44433495e-02 -3.56180828e-01  6.07203156e-02 -8.88546940e-02\n",
      "   2.77990891e-02 -5.58260923e-03]]\n",
      "[-1.62882168]\n",
      "\n",
      " Accuracy by admission status\n",
      "Class       0    1\n",
      "row_0             \n",
      "0      284240  203\n",
      "1          75  289\n",
      "\n",
      " Percentage accuracy\n",
      "0.9990239003957065\n"
     ]
    }
   ],
   "source": [
    "# Declare a ridge regression classifier.\n",
    "ridge_reg = LogisticRegression(penalty='l2', C=20)\n",
    "\n",
    "# Fit the model.\n",
    "ridge_fit = ridge_reg.fit(X, y)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(ridge_fit.coef_)\n",
    "print(ridge_fit.intercept_)\n",
    "pred_y_sklearn = ridge_reg.predict(X)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(ridge_reg.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge - logistic regression produced a detection fraud percent of 20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 30)\n",
      "Shape of y: (284807, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.ix[:, df.columns != 'Class'])\n",
    "y = np.array(df.ix[:, df.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test sizes.\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "\n",
    "y_train = df_train['Class'].values.reshape(-1,1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['Class'])]\n",
    "\n",
    "Y_test = df_test['Class'].values.reshape(-1,1)\n",
    "X_test = df_test.loc[:, ~(df_train.columns).isin(['Class'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\Conda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train4 = svm.predict(data_train)\n",
    "y_pred_test4 = svm.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142129</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1\n",
       "Class             \n",
       "0      142129    5\n",
       "1          41  228"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(target_train, y_pred_train4)\n",
    "#Training data 15.2% fraud detection percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142136</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0   1\n",
       "Class            \n",
       "0      142136  45\n",
       "1         134  89"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(target_test, y_pred_test4)\n",
    "#Testing data 60.0% fraud detection percentage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The SVM test showed poor results with regarding the fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(data_train, target_train)\n",
    "\n",
    "y_pred_train5 = clf.predict(data_train)\n",
    "y_pred_test5 = clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0       0    1     All\n",
      "Class                     \n",
      "0      142111   23  142134\n",
      "1          87  182     269\n",
      "All    142198  205  142403\n"
     ]
    }
   ],
   "source": [
    "table_train = pd.crosstab(target_train, y_pred_train5, margins = True )\n",
    "print(table_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data predicted fraud detection at 32%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0       0    1     All\n",
      "Class                     \n",
      "0      142150   31  142181\n",
      "1         106  117     223\n",
      "All    142256  148  142404\n"
     ]
    }
   ],
   "source": [
    "table_test = pd.crosstab(target_test, y_pred_test5, margins = True )\n",
    "print(table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data predicted a fraud detection at 47% which is really bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0001615134512615605\n",
      "Percent Type II errors: 0.0006109421852067723\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.00021769051431139576\n",
      "Percent Type II errors: 0.0007443611134518693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_tI_errors = table_train.loc[0,1] / table_train.loc['All','All'] \n",
    "train_tII_errors = table_train.loc[1,0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0,1]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1,0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
